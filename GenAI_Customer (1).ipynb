{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcded4-8016-4eb6-9d62-a76b42f92f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. Fake \"Amazon Electronics\" Data (So you don't need to download a huge file yet)\n",
    "data = [\n",
    "    {\"text\": \"The battery life on this phone is terrible. Drains in 4 hours.\", \"category\": \"Battery\", \"sentiment\": \"Negative\"},\n",
    "    {\"text\": \"Amazing camera quality, especially in low light. Best purchase.\", \"category\": \"Camera\", \"sentiment\": \"Positive\"},\n",
    "    {\"text\": \"Screen cracked within a week. Gorilla glass is a lie.\", \"category\": \"Quality\", \"sentiment\": \"Negative\"},\n",
    "    {\"text\": \"Delivery was fast, arrived in 2 days. Packaging was good.\", \"category\": \"Delivery\", \"sentiment\": \"Positive\"},\n",
    "    {\"text\": \"Overpriced for what you get. The processor is slow.\", \"category\": \"Price\", \"sentiment\": \"Negative\"},\n",
    "]\n",
    "\n",
    "print(\"üîÑ Processing data...\")\n",
    "\n",
    "# 2. Convert to LangChain Documents\n",
    "documents = []\n",
    "for item in data:\n",
    "    # We add metadata (category/sentiment) so we can filter later if needed\n",
    "    doc = Document(\n",
    "        page_content=item[\"text\"],\n",
    "        metadata={\"category\": item[\"category\"], \"sentiment\": item[\"sentiment\"]}\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "# 3. Initialize Embedding Model (Runs locally on CPU - Free & Private)\n",
    "# This turns text into numbers (vectors)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Create and Save the Vector Database (ChromaDB)\n",
    "# This creates a folder named \"chroma_db\" in your directory\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Success! Database created in './chroma_db' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b91a29-2c72-4e29-aff1-b7606fa0fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once to force-install everything in the current notebook kernel\n",
    "%pip install langchain langchain-community langchain-core langchain-groq langchain-huggingface langchain-chroma streamlit chromadb pandas sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4247b3-8542-484e-9d21-b18a314be2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to force-install the main library and all dependencies\n",
    "%pip install -U langchain langchain-community langchain-core langchain-groq langchain-chroma chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f1b02-1991-49e9-86c3-1e7887fe750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# ‚ö†Ô∏è REPLACE THIS WITH YOUR NEW KEY (Do not share it!)\n",
    "GROQ_API_KEY = \"ENTER_YOUR_GROQ_API_KEY_HERE\" \n",
    "\n",
    "# --- SETUP PAGE ---\n",
    "st.set_page_config(page_title=\"ReviewSense Dashboard\", layout=\"wide\")\n",
    "st.title(\"ü§ñ ReviewSense: GenAI Customer Insights\")\n",
    "\n",
    "# --- LOAD DATABASE ---\n",
    "@st.cache_resource\n",
    "def load_resources():\n",
    "    # 1. Load Embedding Model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # 2. Connect to Database\n",
    "    vector_db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings)\n",
    "    \n",
    "    # 3. Connect to LLM\n",
    "    llm = ChatGroq(model_name=\"llama3-8b-8192\", groq_api_key=GROQ_API_KEY)\n",
    "    \n",
    "    return vector_db, llm\n",
    "\n",
    "# --- UI LAYOUT ---\n",
    "col1, col2 = st.columns([1, 1])\n",
    "\n",
    "# LEFT COLUMN: RAG Chatbot (Manual Logic - No Chains Required)\n",
    "with col1:\n",
    "    st.header(\"üí¨ Semantic Search\")\n",
    "    user_query = st.text_input(\"Ask a question about the reviews:\")\n",
    "    \n",
    "    if st.button(\"Analyze\") and user_query:\n",
    "        if \"gsk_\" not in GROQ_API_KEY:\n",
    "            st.error(\"Please paste your valid Groq API Key in the code!\")\n",
    "        else:\n",
    "            with st.spinner(\"Thinking...\"):\n",
    "                vector_db, llm = load_resources()\n",
    "                \n",
    "                # STEP 1: RETRIEVE (Search the database manually)\n",
    "                # We ask the DB for the 2 most similar documents\n",
    "                results = vector_db.similarity_search(user_query, k=2)\n",
    "                \n",
    "                # STEP 2: CONTEXT (Combine the text)\n",
    "                context_text = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "                \n",
    "                # STEP 3: GENERATE (Send to LLM manually)\n",
    "                prompt = f\"\"\"\n",
    "                You are a helpful assistant. Answer the user's question using ONLY the context below.\n",
    "                \n",
    "                Context:\n",
    "                {context_text}\n",
    "                \n",
    "                Question: \n",
    "                {user_query}\n",
    "                \"\"\"\n",
    "                \n",
    "                response = llm.invoke(prompt)\n",
    "                \n",
    "                # STEP 4: DISPLAY\n",
    "                st.success(response.content)\n",
    "                \n",
    "                with st.expander(\"See Retrieved Context\"):\n",
    "                    for doc in results:\n",
    "                        st.write(f\"- {doc.page_content}\")\n",
    "\n",
    "# RIGHT COLUMN: Dashboard Analytics\n",
    "with col2:\n",
    "    st.header(\"üìä Defect Trends\")\n",
    "    chart_data = pd.DataFrame({\n",
    "        \"Category\": [\"Battery\", \"Camera\", \"Quality\", \"Delivery\", \"Price\"],\n",
    "        \"Complaints\": [45, 12, 30, 5, 20] \n",
    "    })\n",
    "    st.bar_chart(chart_data.set_index(\"Category\"))\n",
    "    st.caption(\"Automated categorization of 10,000+ reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07904c02-a821-4ff9-90fd-6970ec78158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"1. COPY THIS COMMAND AND RUN IT IN YOUR TERMINAL:\")\n",
    "print(f\"cd {os.getcwd()}\")\n",
    "print(\"\\n2. THEN RUN THIS:\")\n",
    "print(\"streamlit run app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c7424-5b1e-44dd-917f-976cb42c0c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
